{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OrdinalEncoder, StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import optuna\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('./test.csv').drop(columns=['ID'])\n",
    "\n",
    "X_train = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "    \"총 생성 배아 수\",  #used ####\n",
    "    \"미세주입된 난자 수\",\n",
    "    \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\",   #used\n",
    "    \"미세주입 배아 이식 수\",  #####\n",
    "    \"저장된 배아 수\",\n",
    "    \"미세주입 후 저장된 배아 수\",\n",
    "    \"해동된 배아 수\",\n",
    "    \"해동 난자 수\", #used\n",
    "    \"수집된 신선 난자 수\",  #used #####\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"혼합된 난자 수\",   #used #####\n",
    "    \"파트너 정자와 혼합된 난자 수\", #####\n",
    "    \"기증자 정자와 혼합된 난자 수\",\n",
    "    \"난자 채취 경과일\", #####\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 이식 경과일\", #####\n",
    "    \"배아 해동 경과일\"\n",
    "]\n",
    "print(len(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\", #used # most important factor\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",   #used -> eliminated # 없앴더니 성능 감소\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",    #used\n",
    "    \"남성 부 불임 원인\",    #used\n",
    "    \"여성 주 불임 원인\",    #used\n",
    "    \"여성 부 불임 원인\",    #used\n",
    "    \"부부 주 불임 원인\",    #used\n",
    "    \"부부 부 불임 원인\",    #used\n",
    "    \"불명확 불임 원인\", #used # 없 감\n",
    "    \"불임 원인 - 난관 질환\",    #used\n",
    "    \"불임 원인 - 남성 요인\",    #used\n",
    "    \"불임 원인 - 배란 장애\",    #used\n",
    "    \"불임 원인 - 여성 요인\",    #used -> eliminated   # 얘는 그대로\n",
    "    \"불임 원인 - 자궁경부 문제\",    #used\n",
    "    \"불임 원인 - 자궁내막증\",   #used\n",
    "    \"불임 원인 - 정자 농도\",    #used\n",
    "    \"불임 원인 - 정자 면역학적 요인\",   #used -> eliminated # 없앴더니 성능 감소\n",
    "    \"불임 원인 - 정자 운동성\",  #used\n",
    "    \"불임 원인 - 정자 형태\",    #used\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\", #used\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\", #used\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\", #used\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",    #used -> eliminated\n",
    "    \"정자 출처\",    #used -> eliminated\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",  #used\n",
    "    \"신선 배아 사용 여부\",  #used\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Categorical_non_ordinal=[\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\",\n",
    "    \"특정 시술 유형\"\n",
    "] #34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PreProcessing0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Data Drop & Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = ['시술 유형', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', \n",
    "              '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 여성 요인', \n",
    "              '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', \n",
    "              '불임 원인 - 정자 운동성', 'DI 임신 횟수', 'DI 출산 횟수', '동결 배아 사용 여부', \n",
    "              '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부']\n",
    "\n",
    "numeric_columns = list(set(numeric_columns) - set(out_list))\n",
    "categorical_columns = list(set(categorical_columns) - set(out_list))\n",
    "Categorical_non_ordinal = list(set(Categorical_non_ordinal) - set(out_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=out_list)\n",
    "test = test.drop(columns=out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Numeric Drop '''\n",
    "#numeric - 결측치 80% 이상 drop\n",
    "for col in numeric_columns:\n",
    "    print(X_train[col].isnull().sum())\n",
    "numeric_null_columns = [ col for col in numeric_columns if X_train[col].isnull().sum() != 0 ]\n",
    "\n",
    "numeric_null_ratio = X_train[numeric_null_columns].isnull().mean().sort_values(ascending=False)\n",
    "print(numeric_null_ratio)\n",
    "\n",
    "drop_columns = numeric_null_ratio[numeric_null_ratio >= 0.8].index\n",
    "drop_columns = drop_columns.drop('임신 시도 또는 마지막 임신 경과 연수')\n",
    "X_train = X_train.drop(columns=drop_columns)\n",
    "test = test.drop(columns=drop_columns)\n",
    "\n",
    "numeric_columns = list(set(numeric_columns) - set(drop_columns))\n",
    "print(\"📌\"+drop_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Numeric Impute 2 : KNN Imputer for model 2,3'''\n",
    "import joblib \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer_cache_path = \"knn_imputed2.pkl\"\n",
    "\n",
    "try:\n",
    "    X_train_imputed, test_imputed = joblib.load(imputer_cache_path)\n",
    "    print(\"Loaded cached KNN imputed data.\")\n",
    "\n",
    "    ########################################################################\n",
    "    # X_train_imputed = X_train_imputed.drop(columns=out_list)\n",
    "    # test_imputed = test_imputed.drop(columns=out_list)\n",
    "    ########################################################################\n",
    "except FileNotFoundError:\n",
    "    numeric_filled_columns = numeric_null_ratio[numeric_null_ratio < 0.8].index  # 결측치 비율 80% 미만 컬럼 선택\n",
    "    \n",
    "    knn_imputer = KNNImputer(n_neighbors=6)\n",
    "    \n",
    "    X_train_imputed = X_train.copy()\n",
    "    test_imputed = test.copy()\n",
    "    \n",
    "    X_train_imputed[numeric_filled_columns] = knn_imputer.fit_transform(X_train[numeric_filled_columns])\n",
    "    print(\"X_train finish\")\n",
    "    test_imputed[numeric_filled_columns] = knn_imputer.transform(test[numeric_filled_columns])\n",
    "    print(\"All columns imputed.\")\n",
    "    \n",
    "    joblib.dump((X_train_imputed, test_imputed), imputer_cache_path)\n",
    "    print(\"Saved KNN imputed data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed['임신 시도 또는 마지막 임신 경과 연수'] = X_train_imputed['임신 시도 또는 마지막 임신 경과 연수'].fillna(0)\n",
    "test_imputed['임신 시도 또는 마지막 임신 경과 연수'] = test_imputed['임신 시도 또는 마지막 임신 경과 연수'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Numeric Impute only for Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Categorical Drop'''\n",
    "# ordinal / non ordinal categorical columns 구분\n",
    "''' ordinal 의 경우 결측치 무의미 '''\n",
    "''' non ordinal categorical drop '''\n",
    "# 순서가 없는 categorical columns 중 결측치 90% 이상인 columns drop\n",
    "\n",
    "categorical_null_columns = []\n",
    "print(X_train_imputed[Categorical_non_ordinal].isnull().sum())\n",
    "categorical_null_columns = [ col for col in categorical_columns if X_train_imputed[col].isnull().sum() != 0 ]\n",
    "\n",
    "# print(categorical_null_columns)\n",
    "\n",
    "categorical_null_ratio = X_train_imputed[categorical_null_columns].isnull().mean().sort_values(ascending=False)\n",
    "print(categorical_null_ratio)\n",
    "\n",
    "drop_columns = categorical_null_ratio[categorical_null_ratio >= 0.9].index\n",
    "X_train_imputed = X_train_imputed.drop(columns=drop_columns)\n",
    "test_imputed = test_imputed.drop(columns=drop_columns)\n",
    "\n",
    "categorical_columns = list(set(categorical_columns) - set(drop_columns))\n",
    "print(f\"남은 categorical_columns: {categorical_columns}\")\n",
    "print(len(categorical_columns))\n",
    "print(\"📌\"+drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Categorical Impute only for Model 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Categorical Impute2 '''\n",
    "#model3\n",
    "imputer3 = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "X_train_imputed3 = X_train_imputed.copy()\n",
    "test_imputed3 = test_imputed.copy()\n",
    "\n",
    "X_train_imputed3[categorical_columns] = imputer3.fit_transform(X_train_imputed[categorical_columns])\n",
    "test_imputed3[categorical_columns] = imputer3.transform(test_imputed[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이상치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이상치 비율 계산\n",
    "# def calculate_outlier_ratio(data):\n",
    "#     # 각 컬럼에 대해 이상치를 판단하는 함수\n",
    "#     Q1 = np.percentile(data, 25)\n",
    "#     Q3 = np.percentile(data, 75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "#     # 이상치 비율 계산\n",
    "#     outliers = ((data < lower_bound) | (data > upper_bound)).sum()\n",
    "#     total = len(data)\n",
    "#     return outliers / total\n",
    "\n",
    "# # 이상치 비율 계산\n",
    "# outlier_ratios = {}\n",
    "# for column in numeric_columns:\n",
    "#     outlier_ratios[column] = calculate_outlier_ratio(X_train_imputed[column])\n",
    "\n",
    "# # 이상치 비율 출력\n",
    "# for column, ratio in outlier_ratios.items():\n",
    "#     print(f\"{column}의 이상치 비율: {ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "\n",
    "# print(f\"LOF 적용 전 데이터 크기: {X_train_imputed3.shape}\")\n",
    "\n",
    "# lof = LocalOutlierFactor(n_neighbors=30, contamination=0.07)\n",
    "# outliers = lof.fit_predict(X_train_imputed3[numeric_columns])\n",
    "\n",
    "# X_train_imputed3 = X_train_imputed3[outliers == 1]\n",
    "# y = y[outliers == 1]\n",
    "\n",
    "# print(f\"LOF 적용 후 데이터 크기: {X_train_imputed3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3 Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train_imputed3.copy()\n",
    "test_scaled = test_imputed3.copy()\n",
    "\n",
    "X_train_scaled[numeric_columns] = scaler.fit_transform(X_train_imputed3[numeric_columns])\n",
    "test_scaled[numeric_columns] = scaler.transform(test_imputed3[numeric_columns])\n",
    "print(X_train_imputed3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. PreProcessing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train_imputed3[numeric_columns]\n",
    "test_numeric = test_imputed3[numeric_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_numeric)\n",
    "test_scaled = scaler.transform(test_numeric)\n",
    "\n",
    "# PCA 적용 (설정: 분산을 95% 유지하는 주성분 개수 자동 선택)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "test_pca = pca.transform(test_scaled)\n",
    "\n",
    "# PCA 결과를 데이터프레임으로 변환\n",
    "X_train_pca = pd.DataFrame(X_train_pca, columns=[f'PC{i+1}' for i in range(X_train_pca.shape[1])])\n",
    "test_pca = pd.DataFrame(test_pca, columns=[f'PC{i+1}' for i in range(test_pca.shape[1])])\n",
    "\n",
    "# PCA 설명된 분산 비율 확인\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = explained_variance.cumsum()\n",
    "num_components = len(cumulative_variance)\n",
    "\n",
    "print(f\"PCA :  사용된 주성분 개수: {num_components}\")\n",
    "print(f\"설명된 분산 비율 (누적): {cumulative_variance[-1]:.4f}\")\n",
    "\n",
    "# 기존 데이터에서 숫자형 부분을 PCA 결과로 교체\n",
    "X_train_imputed3.update(X_train_pca)\n",
    "test_imputed3.update(test_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 세제곱 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(set(numeric_columns)-set(['이식된 배아 수'])):\n",
    "  X_train_imputed3[col] = X_train_imputed3[col] ** 2\n",
    "  test_imputed3[col] = test_imputed3[col] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Feature 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3-1. 단순 생성성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed3['시술 시점'] = X_train_imputed3['시술 시기 코드'] + '_' + X_train_imputed3['시술 당시 나이']\n",
    "test_imputed3['시술 시점'] = test_imputed3['시술 시기 코드'] + '_' + test_imputed3['시술 당시 나이']\n",
    "categorical_columns.append('시술 시점')\n",
    "Categorical_non_ordinal.append('시술 시점')\n",
    "\n",
    "# X_train_imputed3['배아 정보'] = (X_train_imputed3['총 생성 배아 수'] * X_train_imputed3['해동된 배아 수'])\n",
    "# numeric_columns.append('배아 정보')\n",
    "\n",
    "# print(X_train_imputed['배아 정보']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-3-2. 결측치 보완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_newf = X_train_imputed3.copy()\n",
    "test_newf = test_imputed3.copy()\n",
    "y_train3 = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' train / valid 구분 '''  #70% train\n",
    "#model3\n",
    "X_train3 = X_train_newf[:int(X_train.shape[0]*0.7):]\n",
    "X_valid3 = X_train_newf[int(X_train.shape[0]*0.7):]\n",
    "y_train3 = y[:int(X_train.shape[0]*0.7):]\n",
    "y_valid3 = y[int(X_train.shape[0]*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model 3 '''\n",
    "\n",
    "#categorical str transform\n",
    "for col in categorical_columns:\n",
    "    # print(type(X_train[col]))\n",
    "    \n",
    "    X_train3[col] = X_train3[col].astype(str)\n",
    "    X_valid3[col] = X_valid3[col].astype(str)\n",
    "    # test[col] = test[col].astype(str)\n",
    "\n",
    "# print(X_train3[categorical_columns].dtypes)\n",
    "\n",
    "#pool\n",
    "''' categorical 내장 encoding '''\n",
    "train_pool = Pool(data = X_train3, label = y_train3, cat_features = categorical_columns)\n",
    "val_pool = Pool(data = X_valid3, label = y_valid3, cat_features = categorical_columns)\n",
    "\n",
    "# classes = np.unique(y_train3)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train3)\n",
    "# class_weights = dict(zip(classes, weights))\n",
    "\n",
    "#fitting\n",
    "model3 = CatBoostClassifier(cat_features = categorical_columns, random_state = 42, silent=True, eval_metric='AUC')\n",
    "model3.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "y_pred_prob = model3.predict_proba(X_valid3)[:, 1]\n",
    "auc_score = roc_auc_score(y_valid3, y_pred_prob)\n",
    "print(f\"Validation AUC-ROC: {auc_score:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model 3 '''\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# categorical 변수 문자열 변환\n",
    "for col in categorical_columns:\n",
    "    X_train3[col] = X_train3[col].astype(str)\n",
    "    X_valid3[col] = X_valid3[col].astype(str)\n",
    "\n",
    "# CatBoost Pool 생성\n",
    "train_pool = Pool(data=X_train3, label=y_train3, cat_features=categorical_columns)\n",
    "val_pool = Pool(data=X_valid3, label=y_valid3, cat_features=categorical_columns)\n",
    "\n",
    "# 최적의 하이퍼파라미터 적용\n",
    "best_params = {\n",
    "    'n_estimators': 1600,\n",
    "    'learning_rate': 0.022269562365768235,\n",
    "    'depth': 6,\n",
    "    'subsample': 0.8570762892949296,\n",
    "    'l2_leaf_reg': 2.736528145798781,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'colsample_bylevel': 0.7609486820290322,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'early_stopping_rounds': 70,\n",
    "    'eval_metric': 'AUC',\n",
    "    'random_state': 42,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# 모델 학습\n",
    "model3 = CatBoostClassifier(cat_features=categorical_columns, **best_params)\n",
    "model3.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_prob = model3.predict_proba(X_valid3)[:, 1]\n",
    "auc_score = roc_auc_score(y_valid3, y_pred_prob)\n",
    "print(f\"Validation AUC-ROC: {auc_score:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    X_train3[col] = X_train3[col].astype(str)\n",
    "    X_valid3[col] = X_valid3[col].astype(str)\n",
    "\n",
    "#pool\n",
    "''' categorical 내장 encoding '''\n",
    "train_pool = Pool(data = X_train3, label = y_train3, cat_features = categorical_columns)\n",
    "val_pool = Pool(data = X_valid3, label = y_valid3, cat_features = categorical_columns)\n",
    "\n",
    "classes = np.unique(y_train3)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train3)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Objective 함수\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # 트리 개수: 학습 속도와 성능의 균형을 위해 적당한 범위\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 2000, step=200),\n",
    "\n",
    "        # 학습률: 안정성과 속도의 균형을 위해 작은 범위\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n",
    "\n",
    "        # 트리 깊이: 가장 효과적인 깊이 범위\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 10),\n",
    "\n",
    "        # 부분 샘플링 비율: 과적합 방지를 위해 일반적인 범위\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 0.9),\n",
    "\n",
    "        # 정규화: 적은 값과 큰 값 모두 탐색 가능하게 설정\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 2, 10),\n",
    "\n",
    "        # 리프당 최소 샘플 수: 적당한 범위로 설정\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 50, step=5),\n",
    "\n",
    "        # 트리 수준별 샘플링 비율: 일반적인 범위\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.7, 1.0),\n",
    "\n",
    "        # 부트스트랩 방법: 가장 자주 사용되는 옵션만 제공\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "\n",
    "        # 클래스 불균형 처리\n",
    "        \"class_weights\": class_weights,\n",
    "\n",
    "        # 범주형 변수 지정\n",
    "        \"cat_features\": categorical_columns,\n",
    "\n",
    "        # 평가 지표\n",
    "        \"eval_metric\": \"AUC\",\n",
    "\n",
    "        # 조기 중단\n",
    "        \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 30, 70, step=10),\n",
    "\n",
    "        # 로그 최소화\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "\n",
    "    # Bayesian 방식에서는 subsample 제거\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        del params[\"subsample\"]\n",
    "\n",
    "    cat_model = CatBoostClassifier(**params)\n",
    "    cat_model.fit(train_pool, eval_set=val_pool)\n",
    "    val_pred = cat_model.predict_proba(X_valid3)[:, 1]\n",
    "\n",
    "    return roc_auc_score(y_valid3, val_pred)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X_train_newf[col] = X_train_newf[col].astype(str)\n",
    "\n",
    "\n",
    "# KFold 설정\n",
    "N_SPLITS = 5  # 5-Fold Cross Validation\n",
    "kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "classes = np.unique(y_train3)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train3)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Optuna Objective 함수 정의\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        # 트리 개수: 학습 속도와 성능의 균형을 위해 적당한 범위\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 2000, step=200),\n",
    "\n",
    "        # 학습률: 안정성과 속도의 균형을 위해 작은 범위\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n",
    "\n",
    "        # 트리 깊이: 가장 효과적인 깊이 범위\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 10),\n",
    "\n",
    "        # 부분 샘플링 비율: 과적합 방지를 위해 일반적인 범위\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 0.9),\n",
    "\n",
    "        # 정규화: 적은 값과 큰 값 모두 탐색 가능하게 설정\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 2, 10),\n",
    "\n",
    "        # 리프당 최소 샘플 수: 적당한 범위로 설정\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 50, step=5),\n",
    "\n",
    "        # 트리 수준별 샘플링 비율: 일반적인 범위\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.7, 1.0),\n",
    "\n",
    "        # 부트스트랩 방법: 가장 자주 사용되는 옵션만 제공\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "\n",
    "        # 클래스 불균형 처리\n",
    "        \"class_weights\": class_weights,\n",
    "\n",
    "        # 범주형 변수 지정\n",
    "        \"cat_features\": categorical_columns,\n",
    "\n",
    "        # 평가 지표\n",
    "        \"eval_metric\": \"AUC\",\n",
    "\n",
    "        # 조기 중단\n",
    "        \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 30, 70, step=10),\n",
    "\n",
    "        # 로그 최소화\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "\n",
    "    # Bayesian 방식에서는 subsample 제거\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        del params[\"subsample\"]\n",
    "\n",
    "    # K-Fold Cross Validation 수행\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X_train_newf, y_train3):\n",
    "        X_tr, X_val = X_train_newf.iloc[train_idx], X_train_newf.iloc[valid_idx]\n",
    "        y_tr, y_val = y_train3.iloc[train_idx], y_train3.iloc[valid_idx]\n",
    "\n",
    "        train_pool = Pool(data=X_tr, label=y_tr, cat_features=categorical_columns)\n",
    "        val_pool = Pool(data=X_val, label=y_val, cat_features=categorical_columns)\n",
    "\n",
    "        # 모델 학습\n",
    "        cat_model = CatBoostClassifier(**params)\n",
    "        cat_model.fit(train_pool, eval_set=val_pool)\n",
    "\n",
    "        # 검증 데이터 예측\n",
    "        val_pred = cat_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        # AUC 점수 저장\n",
    "        auc_scores.append(roc_auc_score(y_val, val_pred))\n",
    "\n",
    "    # 평균 AUC 반환\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "# Optuna Study 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model 3 '''\n",
    "#categorical str transform\n",
    "for col in categorical_columns:\n",
    "    X_train_newf[col] = X_train_newf[col].astype(str)\n",
    "    test_newf[col] = test_newf[col].astype(str)\n",
    "\n",
    "#pool\n",
    "''' categorical 내장 encoding '''\n",
    "train_pool = Pool(data = X_train_newf, label = y, cat_features = categorical_columns)\n",
    "\n",
    "# classes = np.unique(y)\n",
    "# weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "# class_weights = dict(zip(classes, weights))\n",
    "\n",
    "#fitting\n",
    "model = CatBoostClassifier(cat_features = categorical_columns, random_state = 42, silent=True, eval_metric='AUC')\n",
    "model.fit(train_pool)\n",
    "\n",
    "pred_proba = model.predict_proba(test_newf)[:, 1]\n",
    "\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['probability'] = pred_proba\n",
    "\n",
    "submission.to_csv('./preprocessing_v4-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model 3 '''\n",
    "# categorical 변수 문자열 변환\n",
    "for col in categorical_columns:\n",
    "    X_train_newf[col] = X_train_newf[col].astype(str)\n",
    "    test_newf[col] = test_newf[col].astype(str)\n",
    "\n",
    "# CatBoost Pool 생성\n",
    "train_pool = Pool(data=X_train_newf, label=y, cat_features=categorical_columns)\n",
    "\n",
    "# 최적의 하이퍼파라미터 적용\n",
    "# best_params = {\n",
    "#     'n_estimators': 800,\n",
    "#     'learning_rate': 0.041481707162322246,\n",
    "#     'depth': 6,\n",
    "#     'l2_leaf_reg': 5.192930349370407,\n",
    "#     'min_data_in_leaf': 10,\n",
    "#     'colsample_bylevel': 0.8910668655874581,\n",
    "#     'bootstrap_type': 'Bayesian',\n",
    "#     'early_stopping_rounds': 60,\n",
    "#     'eval_metric': 'AUC',\n",
    "#     'random_state': 42,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "# 모델 학습\n",
    "model = CatBoostClassifier(cat_features=categorical_columns,l2_leaf_reg=5)\n",
    "model.fit(train_pool)\n",
    "\n",
    "# 예측\n",
    "pred_proba = model.predict_proba(test_newf)[:, 1]\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['probability'] = pred_proba\n",
    "\n",
    "submission.to_csv('./preprocessing_v9.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivfcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
